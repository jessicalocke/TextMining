---
title: "Yelp Tidytext Text Mining"
author: "Jessica Locke"
date: "June 25, 2018"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(readr)
library(dplyr)
library(tidytext)
library(stringr)
library(jsonlite)
library(tidyr)
library(igraph)
library(ggraph)
library(widyr)
library(ggplot2)
theme_set(theme_bw())
```

#Yelp data text mining using tidytext


```{r load_data, echo = FALSE}

#read 200K reviews from yelp dataset
infile <- "C:\\Users\\jlocke\\Documents\\Text Mining Data\\dataset\\review.json"
review_lines <- read_lines(infile, n_max = 10000, progress = FALSE)

#format json so each review is 1 row
reviews_combined <- str_c("[", str_c(review_lines, collapse = ", "), "]")

reviews <- fromJSON(reviews_combined) %>%
  flatten() %>%
  tbl_df()

#in order to use tidytext, need to format so that there is one row per term per document

review_words <- reviews %>%
  select(review_id, business_id, stars, text) %>%
  unnest_tokens(word, text) %>%
  filter(!word %in% stop_words$word, str_detect(word, "^[a-z']+$"))


```

#Sentiment analysis

##Using tidytext to find average sentiment using AFINN lexicon
```{r avg_sentiment, echo = FALSE}

AFINN <- sentiments %>%
  filter(lexicon == "AFINN") %>%
  select(word, afinn_score = score)

reviews_sentiment <- review_words %>%
  inner_join(AFINN, by = "word") %>%
  group_by(review_id, stars) %>%
  summarize(sentiment = mean(afinn_score))

#plot the avg sentiment score vs star rating
ggplot(reviews_sentiment, aes(stars, sentiment, group = stars)) +
  geom_boxplot() +
  ylab("Average sentiment score") +
  ggtitle("AFINN sentiment score vs star rating")

```

##Positive vs negative words
```{r pos_neg_words, echo = FALSE}

#per word summary
review_words_counted <- review_words %>%
  count(review_id, business_id, stars, word) %>%
  ungroup()

word_summaries <- review_words_counted %>%
  group_by(word) %>%
  summarize(businesses = n_distinct(business_id),
            reviews = n(),
            uses = sum(n),
            average_stars = mean(stars)) %>%
  ungroup()

word_summaries_filtered <- word_summaries %>%
  filter(reviews >= 200, businesses >= 10)

print("Top 20 most positive words")
word_summaries_filtered %>%
  arrange(desc(average_stars)) %>%
  top_n(20)

print("Top 20 most negative words")
word_summaries_filtered %>%
  arrange(average_stars) %>%
  top_n(-20)

#plot positivity by frequency
ggplot(word_summaries_filtered, aes(reviews, average_stars)) +
  geom_point() +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1, hjust = 1) +
  scale_x_log10() +
  geom_hline(yintercept = mean(reviews$stars), color = "red", lty = 2) +
  xlab("# of reviews") +
  ylab("Average stars") +
  ggtitle("Word positivity by frequency")

```

##Comparing reviews with AFINN word scores

```{r review_vs_afinn, echo = FALSE}

#df of the afinn words that appear in reviews, along with review details, including stars
words_afinn <- word_summaries_filtered %>%
  inner_join(AFINN)

#box plot of afinn scores vs review rating
ggplot(words_afinn, aes(afinn_score, average_stars, group = afinn_score)) +
  geom_boxplot() +
  xlab("AFINN score of word") +
  ylab("Average stars of reviews with this word") +
  ggtitle("Word AFINN scores vs review star rating")

#plot of which positive/negative words most successful in predicting positive/negative review
words_afinn %>%
  arrange(desc(reviews)) %>%
  ggplot(aes(afinn_score, average_stars)) +
  geom_point(aes(size = reviews)) +
  geom_text(aes(label = word), vjust = 1, hjust = 1, check_overlap = TRUE) +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("AFINN Sentiment Score") +
  ylab("Average Yelp stars") +
  ggtitle("AFINN score vs review star rating") +
  expand_limits(x = -6)

word_summaries_filtered %>%
  inner_join(AFINN, by = "word") %>%
  ggplot(aes(reviews, average_stars, color = afinn_score)) +
  geom_point() +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1, hjust = 1) +
  scale_x_log10() +
  geom_hline(yintercept = mean(reviews$stars), color = "red", lty = 2) +
  scale_color_gradient2(low = "red", high = "blue", midpoint = 0, mid = "gray") +
  labs(x = "# of reviews",
       y = "Average Stars",
       color = "AFINN",
       title = 'Star rating vs word frequency and AFINN')


```
#Term frequency

##Term frequency by star rating
```{r term_freq, echo = FALSE}

review_words_freq <- review_words %>%
  count(stars, word, sort = TRUE) %>%
  ungroup()

total_words <- review_words_freq %>% 
  group_by(stars) %>% 
  summarize(total = sum(n))

review_words_freq <- left_join(review_words_freq, total_words)

ggplot(review_words_freq, aes(n/total, fill = stars)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.0009) +
  facet_wrap(~stars, ncol = 2, scales = "free_y")

```

##Zipf's Law
```{r zipf, echo = FALSE}

freq_by_rank <- review_words_freq %>% 
  group_by(stars) %>% 
  mutate(rank = row_number(), 
         `term frequency` = n/total)

freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = stars)) + 
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()

```

##Tf/itf
```{r tf_itf, echo = FALSE}

review_words_freq <- review_words_freq %>%
  bind_tf_idf(word, business_id, n)

review_words_freq %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  group_by(book) %>% 
  top_n(15) %>% 
  ungroup %>%
  ggplot(aes(word, tf_idf, fill = book)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~book, ncol = 2, scales = "free") +
  coord_flip()

```

#Using n-grams to find relationships between words

##Working with bigrams
```{r create_bigrams, echo = FALSE}

#Create bigrams
bigrams_separated <-  reviews %>%
  select(review_id, business_id, stars, text) %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  #filter out bigrams that include a stopword
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) 

#Combine bigram columns back into 1 field
bigrams_united <- bigrams_separated %>%
  unite(bigram, word1, word2, sep = " ")


#Print the 20 most common bigrams
print("Top 20 most common bigrams")
bigrams_united %>% 
  count(bigram, sort = TRUE) %>%
  arrange(desc(n)) %>%
  top_n(20)

#looking at negation words

#Create bigrams including stopwords
bigrams_separated_with_stop <-  reviews %>%
  select(review_id, business_id, stars, text) %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
  separate(bigram, c("word1", "word2"), sep = " ")

negation_words <- c("not", "no", "never", "without")

negated_words <- bigrams_separated_with_stop %>%
  filter(word1 %in% negation_words) %>%
  inner_join(AFINN, by = c(word2 = "word")) %>%
  count(word1, word2, afinn_score, sort = TRUE) %>%
  ungroup()

negated_words %>%
  group_by(word1) %>%
  arrange(desc(n)) %>%
  filter(row_number() <= 10) %>%
  ungroup() %>%
  mutate(afinn_n = afinn_score * n) %>%
  ggplot(aes(x = reorder(word2,afinn_n), y = afinn_n)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~word1, scales = "free") +
  labs(y = "AFINN score * n",
       x = "Top 10 words associated with negation word") +
  coord_flip()



```

##Graphing bigrams using igraph and ggraph
```{r graphing_bigrams, echo = FALSE, height = 9, width = 10}

#df of bigram counts
bigram_counts <- bigrams_separated %>% 
  count(word1, word2, sort = TRUE)

# filter for only relatively common combinations
bigram_graph <- bigram_counts %>%
  filter(n > 30) %>%
  graph_from_data_frame()

#use ggraph to graph the bigram_graph
set.seed(2017)

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link() +
  geom_node_point() +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1)

a <- grid::arrow(type = "closed", length = unit(.05, "inches"))

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.05, 'inches')) +
  geom_node_point(color = "lightblue", size = 5) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()

```
##Counting and correlating pairs

```{r correlation, echo = FALSE}

business_words <- review_words %>%
  select(-review_id) %>%
  filter(!word %in% stop_words$word)

#count words co-occuring within businesses
#filter for at least relatively common words
word_cors <- review_words %>%
  group_by(word) %>%
  filter(n() >= 20) %>%
  pairwise_cor(word, business_id, sort = TRUE)

word_cors %>%
  filter(item1 %in% c("friendly", "service", "bad", "wait")) %>%
  group_by(item1) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(item2 = reorder(item2, correlation)) %>%
  ggplot(aes(item2, correlation)) +
  geom_bar(stat = "identity") +
  facet_wrap(~ item1, scales = "free") +
  coord_flip() +
  ggtitle("Top 10 words most correlated with specific terms")

#graphing word correlations
# set.seed(2016)
# 
# word_cors %>%
#   filter(correlation > .15) %>%
#   graph_from_data_frame() %>%
#   ggraph(layout = "fr") +
#   geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
#   geom_node_point(color = "lightblue", size = 5) +
#   geom_node_text(aes(label = name), repel = TRUE) +
#   theme_void()



```


```{r template, echo = FALSE}


```

